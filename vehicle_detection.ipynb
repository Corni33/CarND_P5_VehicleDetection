{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- import labeled data set\n",
    "-- use all data, then take care about multiple similar looking images\n",
    "- split into train / test sets\n",
    "- train classifier\n",
    "- test classifier\n",
    "\n",
    "------------\n",
    "ideas:\n",
    "- train convnet on HOG features \n",
    "- train convnet on hog_image (?) -> does this make sense? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of vehicle images: 2826\n",
      "number of non-vehicle images: 3900\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_images(image_dir_list):\n",
    "    \n",
    "    images = []\n",
    "    for img_dir in image_dir_list:    \n",
    "    \n",
    "        # get all image files in the current directory\n",
    "        img_file_list = glob.glob('./training_data/' + img_dir + '/?*.png')\n",
    "\n",
    "        for img_file in img_file_list:\n",
    "            img = cv2.imread(img_file)        \n",
    "            images.append(img)\n",
    "            #images.append(np.ravel(img))\n",
    "            \n",
    "    return images    \n",
    "    \n",
    "# define image data directories\n",
    "vehicle_dirs = ['vehicles/GTI_Far', 'vehicles/GTI_Left', 'vehicles/GTI_MiddleClose', \n",
    "                'vehicles/GTI_Right'] #, 'vehicles/KITTI_extracted']\n",
    "non_vehicle_dirs = ['non-vehicles/GTI']#, 'non-vehicles/Extras']\n",
    "\n",
    "# read vehicle and non-vehicle images\n",
    "vehicle_images = read_images(vehicle_dirs)\n",
    "non_vehicle_images = read_images(non_vehicle_dirs)\n",
    "\n",
    "        \n",
    "print('number of vehicle images: {}'.format(len(vehicle_images)))   \n",
    "print('number of non-vehicle images: {}'.format(len(non_vehicle_images)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_hog_feature_map(img, plot_result=False):\n",
    "    pix_per_cell = 8\n",
    "    cell_per_block = 2\n",
    "    num_orientations = 9     \n",
    "\n",
    "    features, hog_image = hog(img, orientations=num_orientations, pixels_per_cell=(pix_per_cell, pix_per_cell), \n",
    "                              cells_per_block=(cell_per_block, cell_per_block), block_norm='L2-Hys',\n",
    "                              visualise=True, feature_vector=False)\n",
    "\n",
    "    if plot_result:\n",
    "        fig = plt.figure()\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title('Example Car Image')\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(hog_image, cmap='gray')\n",
    "        plt.title('HOG Visualization')\n",
    "        plt.show()\n",
    "    \n",
    "    return features, hog_image\n",
    "\n",
    "def get_hog_feature_vec(img):\n",
    "    pix_per_cell = 8\n",
    "    cell_per_block = 2\n",
    "    num_orientations = 9     \n",
    "\n",
    "    feature_vec = hog(img, orientations=num_orientations, pixels_per_cell=(pix_per_cell, pix_per_cell), \n",
    "                      cells_per_block=(cell_per_block, cell_per_block), block_norm='L2-Hys',\n",
    "                      visualise=False, feature_vector=True)\n",
    "\n",
    "    return feature_vec\n",
    "\n",
    "def plot_feature_vec(feature_vec):\n",
    "    plt.bar(np.arange(0, len(feature_vec)), feature_vec)\n",
    "    plt.show()\n",
    "    \n",
    "def normalize_vec(feature_vec):\n",
    "    # Reshape the vector\n",
    "    vector = feature_vec.reshape(-1, 1)\n",
    "    # Create the scaler for normalization\n",
    "    scaler = StandardScaler().fit(vector)\n",
    "    # Apply the scaler \n",
    "    scaled_vec = scaler.transform(vector)\n",
    "    \n",
    "    return scaled_vec\n",
    "        \n",
    "def convert_to_gray(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def extract_features(images):\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    for img in images:\n",
    "        img = convert_to_gray(img)\n",
    "        feature_vec = get_hog_feature_vec(img)\n",
    "        features.append(normalize_vec(feature_vec))\n",
    "        \n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = vehicle_images[100]\n",
    "#img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#feature_vec = get_hog_feature_vec(img)\n",
    "#plot_feature_vec(feature_vec)\n",
    "\n",
    "# extract features from images\n",
    "vehicle_features = extract_features(vehicle_images)  \n",
    "non_vehicle_features = extract_features(non_vehicle_images)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tobias\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Tobias\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SVC' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-0129792d3a90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m#classifier.fit(X_train, y_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'finished training!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'SVC' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# create input data 'X' from features\n",
    "X = np.vstack((vehicle_features, non_vehicle_features))\n",
    "X = X.reshape((X.shape[0], X.shape[1]))\n",
    "#print(X.shape)\n",
    "\n",
    "# create output labels 'y': 1=vehicle, 0=non-vehicle\n",
    "vehicle_labels = np.ones((len(vehicle_features)))\n",
    "non_vehicle_labels = np.zeros((len(non_vehicle_features)))\n",
    "y = np.hstack((vehicle_labels, non_vehicle_labels))\n",
    "#print(y.shape)\n",
    "\n",
    "# shuffle the data\n",
    "X, y = shuffle(X, y)\n",
    "\n",
    "# split data into training and test set\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# train a SVM for classification by performing a grid search in parameter space\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 3, 5, 7, 9]}\n",
    "svc = svm.SVC()\n",
    "classifier = GridSearchCV(svc, parameters)\n",
    "classifier.fit(X_train, y_train)  \n",
    "\n",
    "print('finished training!')\n",
    "print(classifier.best_params_) # {'C': 5, 'kernel': 'rbf'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9829123328380386\n"
     ]
    }
   ],
   "source": [
    "def calculate_test_accuracy(features, labels):\n",
    "    global classifier\n",
    "    \n",
    "    pred = classifier.predict(features)\n",
    "    num_correct = np.count_nonzero(pred == y_test)\n",
    "    acc = 1.0*num_correct/len(y_test)\n",
    "            \n",
    "    return acc\n",
    "            \n",
    "\n",
    "acc = calculate_test_accuracy(X_test, y_test)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 5, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 3 6] [2 1] [55 44 33 66] [22 11]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
